===./config/__init__.py===

===./config/settings.py===
import os
from pathlib import Path
from dotenv import load_dotenv

# Load .env file BEFORE accessing environment variables
env_path = Path(__file__).parent.parent / '.env'
load_dotenv(dotenv_path=env_path)

class Config:
    # API Keys
    SUPABASE_URL = os.getenv("SUPABASE_URL")
    SUPABASE_KEY = os.getenv("SUPABASE_KEY")
    ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")
    SEEDREAM_API_KEY = os.getenv("SEEDREAM_API_KEY")
    SEEDREAM_ENDPOINT = os.getenv("SEEDREAM_ENDPOINT")
    
    # Google Drive Configuration
    GOOGLE_DRIVE_CREDENTIALS_PATH = os.getenv("GOOGLE_DRIVE_CREDENTIALS_PATH")
    GOOGLE_DRIVE_ROOT_FOLDER_ID = os.getenv("GOOGLE_DRIVE_ROOT_FOLDER_ID")
    
    # Paths
    BASE_DIR = Path(__file__).parent.parent
    OUTPUT_DIR = BASE_DIR / "output"
    FRAMES_DIR = OUTPUT_DIR / "frames"
    VIDEOS_DIR = OUTPUT_DIR / "videos"
    TEMP_DIR = OUTPUT_DIR / "temp"
    FONTS_DIR = BASE_DIR / "fonts"
    FONT_PATH = FONTS_DIR / "MaruBuri-Bold.ttf"
    
    # Video settings
    VIDEO_WIDTH = 1080
    VIDEO_HEIGHT = 1920
    IMAGE_SIZE = 1080
    FPS = 30
    
    # Layout settings
    IMAGE_TOP_PADDING = 150
    TEXT_START_Y = 1270  # 150 + 1080 + 40
    TEXT_SPACING = 78    # 30px between lines + 48px font size
    FONT_SIZE = 55
    TEXT_COLOR = (255, 255, 255)  # White
    
    @classmethod
    def create_directories(cls):
        """Create necessary directories if they don't exist"""
        cls.FRAMES_DIR.mkdir(parents=True, exist_ok=True)
        cls.VIDEOS_DIR.mkdir(parents=True, exist_ok=True)
        cls.TEMP_DIR.mkdir(parents=True, exist_ok=True)

config = Config()
===./main2.py===
"""
Batch Video Generator
Process all published Korean songs and generate videos for lines 1-8
"""

from main import generate_lyric_video
from utils.supabase_client import SupabaseClient
from config.settings import config
import time
from datetime import datetime

def get_all_published_korean_songs():
    """Fetch all published Korean songs from Supabase"""
    supabase = SupabaseClient()
    
    print("üì• Fetching all published Korean songs from database...")
    
    response = (
        supabase.client.table("songs")
        .select("id, title, language, is_published")
        .eq("is_published", True)
        .eq("language", "korean")
        .order("created_at", desc=True)  # Newest first
        .execute()
    )
    
    songs = response.data
    print(f"‚úì Found {len(songs)} published Korean songs\n")
    
    return songs

def process_all_songs():
    """Process all songs and generate videos"""
    
    print("=" * 80)
    print("üé¨ BATCH VIDEO GENERATOR - ALL KOREAN SONGS")
    print("=" * 80)
    print(f"Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    # Fetch all songs
    songs = get_all_published_korean_songs()
    
    if len(songs) == 0:
        print("‚ùå No songs found!")
        return
    
    # Configuration
    START_LINE = 1
    END_LINE = 8
    UPLOAD_TO_DRIVE = True
    DELETE_AFTER_UPLOAD = True
    
    print("‚öôÔ∏è  CONFIGURATION:")
    print(f"  Lines: {START_LINE} to {END_LINE}")
    print(f"  Upload to Drive: {UPLOAD_TO_DRIVE}")
    print(f"  Delete after upload: {DELETE_AFTER_UPLOAD}")
    print()
    
    # Stats tracking
    successful = []
    failed = []
    skipped = []
    
    # Process each song
    for idx, song in enumerate(songs, 1):
        song_id = song['id']
        title = song['title']
        
        print("\n" + "=" * 80)
        print(f"üìÄ PROCESSING {idx}/{len(songs)}: {title}")
        print(f"   Song ID: {song_id}")
        print("=" * 80)
        
        try:
            # Check if video already exists in Drive (optional check)
            # You can add logic here to skip songs that are already processed
            
            # Generate video
            start_time = time.time()
            
            generate_lyric_video(
                song_id=song_id,
                start_line=START_LINE,
                end_line=END_LINE,
                upload_to_drive=UPLOAD_TO_DRIVE,
                delete_after_upload=DELETE_AFTER_UPLOAD
            )
            
            elapsed = time.time() - start_time
            
            successful.append({
                'song_id': song_id,
                'title': title,
                'time': elapsed
            })
            
            print(f"\n‚úÖ SUCCESS! Completed in {elapsed:.1f}s")
            
        except Exception as e:
            print(f"\n‚ùå FAILED: {e}")
            failed.append({
                'song_id': song_id,
                'title': title,
                'error': str(e)
            })
            
            # Continue with next song even if this one fails
            print("   ‚Üí Continuing with next song...")
        
        # Add a small delay between songs to avoid rate limits
        if idx < len(songs):
            print("\n‚è≥ Waiting 5 seconds before next song...")
            time.sleep(5)
    
    # Final Report
    print("\n\n" + "=" * 80)
    print("üìä BATCH PROCESSING COMPLETE!")
    print("=" * 80)
    print(f"Finished at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    print(f"‚úÖ Successful: {len(successful)}/{len(songs)}")
    print(f"‚ùå Failed: {len(failed)}/{len(songs)}")
    print(f"‚è≠Ô∏è  Skipped: {len(skipped)}/{len(songs)}")
    
    if successful:
        print("\n" + "-" * 80)
        print("‚úÖ SUCCESSFUL SONGS:")
        print("-" * 80)
        for s in successful:
            print(f"  ‚úì {s['title']} ({s['time']:.1f}s)")
    
    if failed:
        print("\n" + "-" * 80)
        print("‚ùå FAILED SONGS:")
        print("-" * 80)
        for f in failed:
            print(f"  ‚úó {f['title']}")
            print(f"    Error: {f['error']}")
    
    # Save report to file
    report_path = config.VIDEOS_DIR / f"batch_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("BATCH VIDEO GENERATION REPORT\n")
        f.write("=" * 80 + "\n\n")
        f.write(f"Total Songs: {len(songs)}\n")
        f.write(f"Successful: {len(successful)}\n")
        f.write(f"Failed: {len(failed)}\n")
        f.write(f"Skipped: {len(skipped)}\n\n")
        
        f.write("SUCCESSFUL:\n")
        for s in successful:
            f.write(f"  - {s['title']} (ID: {s['song_id']})\n")
        
        f.write("\nFAILED:\n")
        for fail in failed:
            f.write(f"  - {fail['title']} (ID: {fail['song_id']})\n")
            f.write(f"    Error: {fail['error']}\n")
    
    print(f"\nüìÑ Report saved: {report_path}")
    print("\n" + "=" * 80)

if __name__ == "__main__":
    # Confirm before starting
    print("\n‚ö†Ô∏è  WARNING: This will process ALL published Korean songs!")
    print("   Each video will be uploaded to Drive and local copy deleted.")
    response = input("\n   Continue? (yes/no): ")
    
    if response.lower() in ['yes', 'y']:
        process_all_songs()
    else:
        print("\n‚ùå Cancelled.")
===./agents/style_planner.py===
from utils.claude_client import ClaudeClient
from models.data_models import SongMetadata, LyricLine, StyleGuide, CustomCreativeInput
from typing import List, Optional

class StylePlanner:
    def __init__(self):
        self.claude = ClaudeClient()
    
    def create_style_guide(self, song: SongMetadata, 
                          all_lyrics: List[LyricLine],
                          target_lyrics: List[LyricLine],
                          custom_input: Optional[CustomCreativeInput] = None) -> StyleGuide:
        """Generate style guide for the video segment, using custom input if provided"""
        
        # If custom input provided, use it directly
        if custom_input and custom_input.story_description:
            print("  ‚ÑπÔ∏è  Using custom story description")
            print(f"     Story: {custom_input.story_description[:100]}...")
            
            return StyleGuide(
                visual_style="High-quality Korean webtoon style with clean digital illustration, soft natural colors, expressive faces, modern fashion, atmospheric lighting",
                segment_story=custom_input.story_description,
                is_conversation=custom_input.is_conversation if custom_input.is_conversation is not None else True
            )
        
        # Otherwise, auto-generate as before
        print("  ‚ÑπÔ∏è  Auto-generating story from lyrics")
        
        # Format lyrics as text
        all_lyrics_text = "\n".join([
            f"Line {l.line_number}: {l.english_text} / {l.korean_text}"
            for l in all_lyrics
        ])
        
        target_lyrics_text = "\n".join([
            f"Line {l.line_number}: {l.english_text} / {l.korean_text}"
            for l in target_lyrics
        ])
        
        song_dict = {
            'description': song.description,
            'title': song.title,
            'artist': song.artist
        }
        
        style_data = self.claude.create_style_guide(
            song_dict,
            all_lyrics_text,
            target_lyrics_text
        )
        
        return StyleGuide(**style_data)
===./agents/data_retriever.py===
from utils.supabase_client import SupabaseClient
from models.data_models import SongMetadata, LyricLine, VideoGenerationRequest
from typing import List, Tuple
from pathlib import Path
from config.settings import config

class DataRetriever:
    def __init__(self):
        self.supabase = SupabaseClient()
    
    def fetch_all_data(self, request: VideoGenerationRequest) -> Tuple[SongMetadata, List[LyricLine], List[LyricLine], Path]:
        """
        Fetch all necessary data for video generation
        Returns: (song_metadata, all_lyrics, target_lyrics, audio_file_path)
        """
        # Fetch song metadata
        song = self.supabase.get_song_metadata(request.song_id)
        
        # Fetch all lyrics for context
        all_lyrics = self.supabase.get_all_lyrics_for_context(request.song_id)
        
        # Determine end_line if not specified
        end_line = request.end_line or max(l.line_number for l in all_lyrics)
        
        # Fetch target lyrics
        target_lyrics = self.supabase.get_lyrics(
            request.song_id,
            request.start_line,
            end_line
        )
        
        # Download audio file
        audio_filename = f"song_{request.song_id}.mp3"
        audio_path = config.TEMP_DIR / audio_filename
        
        if not audio_path.exists():
            self.supabase.download_audio_file(song.audio_file_path, audio_path)
        
        return song, all_lyrics, target_lyrics, audio_path
===./agents/reference_selector.py===
from utils.claude_client import ClaudeClient
from models.data_models import LyricLine, StyleGuide
from typing import List
from pathlib import Path

class ReferenceSelector:
    def __init__(self):
        self.claude = ClaudeClient()
        
    def select_references(self, 
                        previous_prompts: List[str],
                        previous_paths: List[Path],
                        current_lyric: dict,
                        style_guide: StyleGuide,
                        line_number: int) -> dict:
        """
        Intelligently select 1-3 reference images that provide style consistency
        without causing compositional repetition
        """
        
        if len(previous_prompts) == 0:
            return {'paths': [], 'indices': [], 'reasoning': 'First image, no references'}
        
        # Format previous prompts for analysis
        prompts_analysis = "\n".join([
            f"Image {i}: {prompt[:150]}..."
            for i, prompt in enumerate(previous_prompts)
        ])
        
        # Ask Claude to select optimal references
        selection = self.claude.select_reference_images(
            prompts_analysis,
            current_lyric,
            style_guide.dict(),
            line_number,
            len(previous_prompts)
        )
        
        # Extract selected indices
        selected_indices = selection.get('selected_indices', [])
        reasoning = selection.get('reasoning', 'No reasoning provided')
        
        print(f"  ‚Üí Reference selection: {selected_indices}")
        print(f"  ‚Üí Reasoning: {reasoning[:100]}...")
        
        # Map indices to paths
        selected_paths = []
        for idx in selected_indices:
            if 0 <= idx < len(previous_paths):
                selected_paths.append(previous_paths[idx])
        
        return {
            'paths': selected_paths,
            'indices': selected_indices,
            'reasoning': reasoning
        }
===./agents/video_compositor.py===
from moviepy.editor import (
    VideoFileClip, ImageClip, TextClip, CompositeVideoClip,
    AudioFileClip, concatenate_videoclips
)
from models.data_models import GeneratedImage, LyricLine
from typing import List
from pathlib import Path
from config.settings import config
from PIL import Image, ImageDraw, ImageFont
import numpy as np
from utils.text_utils import korean_to_romanization

# Fix for Pillow 10.0.0+ compatibility with MoviePy
if not hasattr(Image, 'ANTIALIAS'):
    Image.ANTIALIAS = Image.LANCZOS

class VideoCompositor:
    def __init__(self):
        self.width = config.VIDEO_WIDTH
        self.height = config.VIDEO_HEIGHT
        self.image_size = config.IMAGE_SIZE
        self.fps = config.FPS
    
    def create_text_image(self, text: str, y_position: int) -> np.ndarray:
        """Create an image with text overlay"""
        # Create transparent image
        img = Image.new('RGBA', (self.width, 100), (0, 0, 0, 0))
        draw = ImageDraw.Draw(img)
        
        # Load font
        font = ImageFont.truetype(str(config.FONT_PATH), config.FONT_SIZE)
        
        # Get text bounding box for centering
        bbox = draw.textbbox((0, 0), text, font=font)
        text_width = bbox[2] - bbox[0]
        x_position = (self.width - text_width) // 2
        
        # Draw text
        draw.text((x_position, 10), text, font=font, fill=(255, 255, 255, 255))
        
        return np.array(img)
    
    def create_video_segment(self, image_data: GeneratedImage, 
                            lyric: LyricLine) -> CompositeVideoClip:
        """Create a single video segment with image and text"""
        duration = image_data.end_time - image_data.start_time
        
        # Load and resize image to square
        img_clip = (ImageClip(image_data.image_path)
                   .set_duration(duration)
                   .resize((self.image_size, self.image_size))
                   .set_position(('center', config.IMAGE_TOP_PADDING)))
        
        # Create black background
        bg_clip = (ImageClip(np.zeros((self.height, self.width, 3), dtype=np.uint8))
                  .set_duration(duration))
        
        # Create text clips
        english_clip = (ImageClip(self.create_text_image(lyric.english_text, 0))
                       .set_duration(duration)
                       .set_position(('center', config.TEXT_START_Y)))
        
        korean_clip = (ImageClip(self.create_text_image(lyric.korean_text, 0))
                      .set_duration(duration)
                      .set_position(('center', config.TEXT_START_Y + config.TEXT_SPACING)))
        
        # Get romanization using korean-romanizer
        romanization = korean_to_romanization(lyric.korean_text)
        roman_clip = (ImageClip(self.create_text_image(romanization, 0))
                     .set_duration(duration)
                     .set_position(('center', config.TEXT_START_Y + 2 * config.TEXT_SPACING)))
        
        # Composite all elements
        composite = CompositeVideoClip([
            bg_clip,
            img_clip,
            english_clip,
            korean_clip,
            roman_clip
        ], size=(self.width, self.height))
        
        return composite
    
    def assemble_video(self, images: List[GeneratedImage],
                      lyrics: List[LyricLine],
                      audio_path: Path,
                      output_path: Path) -> Path:
        """Assemble final video with all segments"""
        print("\nüé¨ Assembling video...")
        
        # Create video segments
        segments = []
        for img_data in images:
            # Find corresponding lyric
            lyric = next(l for l in lyrics if l.line_number == img_data.line_number)
            segment = self.create_video_segment(img_data, lyric)
            segments.append(segment)
        
        # Concatenate all segments with crossfade
        print("  ‚Üí Concatenating segments with transitions...")
        final_video = concatenate_videoclips(segments, method="compose")
        
        # Add audio
        print("  ‚Üí Adding audio track...")
        audio = AudioFileClip(str(audio_path))
        
        # Trim audio to match video duration
        start_time = images[0].start_time
        end_time = images[-1].end_time
        audio_segment = audio.subclip(start_time, end_time)
        
        final_video = final_video.set_audio(audio_segment)
        
        # Export
        print(f"  ‚Üí Exporting to {output_path}...")
        final_video.write_videofile(
            str(output_path),
            fps=self.fps,
            codec='libx264',
            audio_codec='aac',
            temp_audiofile=str(config.TEMP_DIR / 'temp-audio.m4a'),
            remove_temp=True,
            threads=4
        )
        
        # Cleanup
        final_video.close()
        audio.close()
        
        print(f"‚úì Video saved to {output_path}")
        return output_path
===./agents/drive_uploader.py===
"""
Simple Drive Uploader
Just uploads video file directly to Google Drive root folder
"""

from pathlib import Path
from typing import Dict
from utils.drive_client import DriveClient
from config.settings import config

class DriveUploader:
    def __init__(self):
        self.drive_client = DriveClient(
            credentials_path=str(config.GOOGLE_DRIVE_CREDENTIALS_PATH),
            root_folder_id=config.GOOGLE_DRIVE_ROOT_FOLDER_ID
        )
    
    def upload_video(self, 
                    video_path: Path,
                    song_id: str,
                    delete_after_upload: bool = True) -> Dict[str, str]:
        """
        Upload video directly to Drive root folder
        
        Args:
            video_path: Path to the video file
            song_id: Song ID (not used for folder creation anymore)
            delete_after_upload: Whether to delete local file after upload
            
        Returns:
            Dictionary with Drive file info
        """
        print("\nüì§ UPLOADING TO GOOGLE DRIVE...")
        
        try:
            # Upload video directly to root folder (no subfolder)
            print(f"  ‚Üí Uploading video: {video_path.name}...")
            video_result = self.drive_client.upload_file(
                file_path=video_path,
                folder_id=self.drive_client.root_folder_id,  # ‚Üê Upload to root!
                make_public=False
            )
            
            print(f"\n‚úÖ Upload complete!")
            print(f"  üé¨ Video: {video_result['web_view_link']}")
            
            # Delete local file if requested
            if delete_after_upload:
                print(f"\nüóëÔ∏è  Deleting local file...")
                size_mb = video_path.stat().st_size / (1024 * 1024)
                video_path.unlink()
                print(f"  ‚úì Deleted: {video_path.name} ({size_mb:.2f} MB freed)")
            
            return {
                'video_file_id': video_result['file_id'],
                'video_link': video_result['web_view_link'],
                'folder_id': self.drive_client.root_folder_id
            }
            
        except Exception as e:
            print(f"\n‚ùå Upload failed: {e}")
            raise
===./agents/__init__.py===

===./agents/image_director.py===
from utils.claude_client import ClaudeClient
from utils.seedream_client import SeedreamClient
from utils.generation_logger import GenerationLogger
from models.data_models import LyricLine, StyleGuide, GeneratedImage, CustomCreativeInput
from typing import List, Tuple, Optional
from pathlib import Path
from config.settings import config
import time
from tqdm import tqdm

class ImageDirector:
    def __init__(self):
        self.claude = ClaudeClient()
        self.seedream = SeedreamClient()
    
    def generate_character_designs(self, style_guide: StyleGuide, song_id: str,
                                  custom_input: Optional[CustomCreativeInput] = None) -> Tuple[List[Path], List[str]]:
        """Generate character design references and return paths + prompts"""
        print("\nüé® GENERATING CHARACTER DESIGNS...")
        
        frames_dir = config.FRAMES_DIR / song_id
        frames_dir.mkdir(parents=True, exist_ok=True)
        
        character_refs = []
        character_prompts = []
        
        # Generate male character
        print("  ‚Üí Generating male character design...")
        if custom_input and custom_input.character_male_description:
            print("  ‚ÑπÔ∏è  Using custom male character description")
            male_prompt = custom_input.character_male_description
        else:
            print("  ‚ÑπÔ∏è  Auto-generating male character design")
            male_prompt = self.claude.generate_character_design(
                style_guide.dict(),
                gender="male"
            )
        
        character_prompts.append(male_prompt)
        print(f"  Prompt: {male_prompt[:100]}...")
        
        male_result = self.seedream.generate_image(
            prompt=male_prompt,
            reference_image_paths=None
        )
        
        male_url = male_result['data'][0]['url']
        male_path = frames_dir / "character_male.jpg"
        self.seedream.download_image(male_url, male_path)
        character_refs.append(male_path)
        print(f"  ‚úì Male character saved: {male_path}")
        
        time.sleep(2)
        
        # Generate female character
        print("  ‚Üí Generating female character design...")
        if custom_input and custom_input.character_female_description:
            print("  ‚ÑπÔ∏è  Using custom female character description")
            female_prompt = custom_input.character_female_description
        else:
            print("  ‚ÑπÔ∏è  Auto-generating female character design")
            female_prompt = self.claude.generate_character_design(
                style_guide.dict(),
                gender="female"
            )
        
        character_prompts.append(female_prompt)
        print(f"  Prompt: {female_prompt[:100]}...")
        
        female_result = self.seedream.generate_image(
            prompt=female_prompt,
            reference_image_paths=None
        )
        
        female_url = female_result['data'][0]['url']
        female_path = frames_dir / "character_female.jpg"
        self.seedream.download_image(female_url, female_path)
        character_refs.append(female_path)
        print(f"  ‚úì Female character saved: {female_path}")
        
        print(f"\n‚úì Character designs complete: {len(character_refs)} references created\n")
        
        return character_refs, character_prompts
    
    def generate_all_images(self, target_lyrics: List[LyricLine],
                           style_guide: StyleGuide,
                           song_id: str,
                           custom_input: Optional[CustomCreativeInput] = None) -> List[GeneratedImage]:
        """Generate all images for the lyric lines"""
        
        generated_images = []
        previous_prompts = []
        
        frames_dir = config.FRAMES_DIR / song_id
        frames_dir.mkdir(parents=True, exist_ok=True)
        
        # Initialize logger
        log_path = config.VIDEOS_DIR / f"generation_log_{song_id}.txt"
        logger = GenerationLogger(log_path)
        logger.log_style_guide(style_guide.dict())
        
        # Log custom input if provided
        if custom_input:
            logger.log("\n=== CUSTOM INPUT PROVIDED ===")
            if custom_input.story_description:
                logger.log(f"Custom Story: {custom_input.story_description}")
            if custom_input.character_male_description:
                logger.log(f"Custom Male Character: {custom_input.character_male_description}")
            if custom_input.character_female_description:
                logger.log(f"Custom Female Character: {custom_input.character_female_description}")
            if custom_input.is_conversation is not None:
                logger.log(f"Is Conversation: {custom_input.is_conversation}")
            logger.log("")
        
        # STEP 1: Generate character designs
        character_refs, character_design_prompts = self.generate_character_designs(
            style_guide, song_id, custom_input
        )
        logger.log("\n=== CHARACTER DESIGNS GENERATED ===")
        logger.log(f"Male: {character_refs[0]}")
        logger.log(f"Male Prompt: {character_design_prompts[0]}\n")
        logger.log(f"Female: {character_refs[1]}")
        logger.log(f"Female Prompt: {character_design_prompts[1]}\n")
        
        total_lines = len(target_lyrics)
        pipeline_start = time.time()
        
        # STEP 2: Generate line images
        for idx, lyric in enumerate(tqdm(target_lyrics, desc="Generating images")):
            print(f"\nüé® Generating image for Line {lyric.line_number}: {lyric.english_text}")
            
            logger.log_line_start(lyric.line_number, lyric.english_text, lyric.korean_text)
            
            start_time = time.time()
            
            if idx == 0:
                print("  ‚Üí Creating first image with character references")
                prompt = self.claude.generate_first_prompt(
                    lyric.dict(),
                    style_guide.dict(),
                    character_design_prompts
                )
                logger.log_prompt_generation(prompt)
                
            else:
                print(f"  ‚Üí Creating image {idx+1} with character references")
                decision = self.claude.generate_next_prompt(
                    previous_prompts,
                    lyric.dict(),
                    style_guide.dict(),
                    character_design_prompts,
                    line_number=lyric.line_number,
                    total_lines=total_lines
                )
                prompt = decision['seedream_prompt']
                reasoning = decision['creative_reasoning']
                
                print(f"  ‚Üí Reasoning: {reasoning[:150]}...")
                logger.log_prompt_generation(prompt, reasoning)
            
            print(f"  ‚Üí Using character design references")
            logger.log(f"  Reference: Character designs (male + female portraits)\n")
            
            # Generate image
            print(f"  ‚Üí Calling Seedream API...")
            try:
                result = self.seedream.generate_image(
                    prompt=prompt,
                    reference_image_paths=character_refs
                )
                
                image_url = result['data'][0]['url']
                image_filename = f"line_{lyric.line_number:03d}.jpg"
                image_path = frames_dir / image_filename
                
                self.seedream.download_image(image_url, image_path)
                
                generation_time = time.time() - start_time
                print(f"  ‚úì Generated in {generation_time:.2f}s ‚Üí {image_path}")
                
                logger.log_generation_result(True, generation_time, str(image_path))
                
                generated_images.append(GeneratedImage(
                    line_number=lyric.line_number,
                    image_path=str(image_path),
                    prompt_used=prompt,
                    start_time=lyric.start_time_seconds,
                    end_time=lyric.end_time_seconds,
                    used_reference=True,
                    reference_image=str(character_refs),
                    generation_time=generation_time
                ))
                
                previous_prompts.append(prompt)
                
            except Exception as e:
                logger.log_generation_result(False, time.time() - start_time, f"ERROR: {str(e)}")
                raise
            
            time.sleep(1)
        
        total_time = time.time() - pipeline_start
        logger.log_summary(len(generated_images), total_time)
        
        print(f"\nüìù Generation log saved to: {log_path}")
        
        return generated_images
===./utils/text_utils.py===
from korean_romanizer.romanizer import Romanizer

def korean_to_romanization(korean_text: str) -> str:
    """
    Convert Korean text to romanization using Revised Romanization of Korean
    """
    try:
        r = Romanizer(korean_text)
        return r.romanize()
    except Exception as e:
        print(f"Warning: Romanization failed for '{korean_text}': {e}")
        return korean_text.lower()  # Fallback
===./utils/seedream_client.py===
import requests
import base64
from pathlib import Path
from config.settings import config
from typing import Optional, List
import time

class SeedreamClient:
    def __init__(self):
        self.api_key = config.SEEDREAM_API_KEY
        self.endpoint = config.SEEDREAM_ENDPOINT
        self.headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }
    
    def generate_image(self, prompt: str, 
                      reference_image_paths: Optional[List[Path]] = None,
                      size: str = "1080x1080") -> dict:
        """Generate image with Seedream API supporting up to 10 reference images"""
        
        # Build negative prompt to prevent unwanted elements
        negative_prompt = (
            "text overlay, korean text, english text, "
            "subtitles, words, letters, captions, typography"
        )
        
        payload = {
            "model": "seedream-4-0-250828",
            "prompt": prompt,
            "negative_prompt": negative_prompt,
            "size": size,
            "sequential_image_generation": "disabled",
            "response_format": "url",
            "watermark": False,
            "stream": False
        }
        
        # Add multiple reference images if provided (max 10)
        if reference_image_paths and len(reference_image_paths) > 0:
            try:
                images_data = []
                
                # Filter valid paths and limit to 10
                valid_paths = [p for p in reference_image_paths if p.exists()][:10]
                
                for img_path in valid_paths:
                    with open(img_path, "rb") as img_file:
                        img_data = base64.b64encode(img_file.read()).decode()
                        
                        # Determine image format
                        ext = img_path.suffix.lower().replace('.', '')
                        if ext == 'jpg':
                            ext = 'jpeg'
                        
                        images_data.append(f"data:image/{ext};base64,{img_data}")
                
                if len(images_data) > 0:
                    # Seedream expects string for 1 image, array for multiple
                    if len(images_data) == 1:
                        payload["image"] = images_data[0]
                    else:
                        payload["image"] = images_data
                    
                    print(f"  ‚Üí Using {len(images_data)} reference image(s) for style consistency")
                    
            except Exception as e:
                print(f"  ‚ö†Ô∏è  Could not load reference images: {e}")
                # Continue without reference
        
        try:
            response = requests.post(
                self.endpoint,
                headers=self.headers,
                json=payload,
                timeout=180
            )
            
            response.raise_for_status()
            return response.json()
            
        except requests.exceptions.RequestException as e:
            print(f"  ‚ùå Seedream API error: {e}")
            if hasattr(e, 'response') and e.response is not None:
                try:
                    error_detail = e.response.json()
                    print(f"  Error details: {error_detail}")
                except:
                    print(f"  Response text: {e.response.text[:200]}")
            raise
    
    def download_image(self, url: str, output_path: Path) -> Path:
        """Download generated image from URL"""
        try:
            response = requests.get(url, timeout=60)
            response.raise_for_status()
            
            output_path.parent.mkdir(parents=True, exist_ok=True)
            output_path.write_bytes(response.content)
            
            return output_path
            
        except requests.exceptions.RequestException as e:
            print(f"  ‚ùå Image download error: {e}")
            raise
===./utils/generation_logger.py===
from pathlib import Path
from datetime import datetime
from typing import List

class GenerationLogger:
    def __init__(self, output_path: Path):
        self.output_path = output_path
        self.output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # Clear file if exists
        with open(self.output_path, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("LYRIC VIDEO GENERATION LOG\n")
            f.write("=" * 80 + "\n\n")
    
    def log(self, content: str):
        """Append content to log file"""
        with open(self.output_path, 'a', encoding='utf-8') as f:
            f.write(content + "\n")
    
    def log_section(self, title: str):
        """Log a section header"""
        self.log("\n" + "=" * 80)
        self.log(title)
        self.log("=" * 80 + "\n")
    
    def log_subsection(self, title: str):
        """Log a subsection header"""
        self.log("\n" + "-" * 80)
        self.log(title)
        self.log("-" * 80 + "\n")
    
    def log_style_guide(self, style_guide: dict):
        """Log the style guide"""
        self.log_section("STYLE GUIDE GENERATION")
        self.log(f"Visual Style:\n{style_guide['visual_style']}\n")
        self.log(f"Story Context:\n{style_guide['segment_story']}\n")
    
    def log_line_start(self, line_number: int, english: str, korean: str):
        """Log the start of a new line generation"""
        self.log_section(f"LINE {line_number}: {english}")
        self.log(f"Korean: {korean}\n")
    
    def log_prompt_generation(self, prompt: str, reasoning: str = None):
        """Log the generated prompt"""
        self.log_subsection("CLAUDE PROMPT GENERATION")
        if reasoning:
            self.log(f"Creative Reasoning:\n{reasoning}\n")
        self.log(f"Seedream Prompt:\n{prompt}\n")
    
    def log_reference_selection(self, selected_indices: List[int], reasoning: str, total_available: int):
        """Log reference selection decision"""
        self.log_subsection("REFERENCE SELECTION")
        self.log(f"Available images: 0-{total_available-1}")
        self.log(f"Selected indices: {selected_indices}")
        self.log(f"Reasoning:\n{reasoning}\n")
    
    def log_generation_result(self, success: bool, generation_time: float, image_path: str):
        """Log the generation result"""
        self.log_subsection("GENERATION RESULT")
        self.log(f"Status: {'SUCCESS' if success else 'FAILED'}")
        self.log(f"Generation Time: {generation_time:.2f}s")
        self.log(f"Image Path: {image_path}\n")
    
    def log_summary(self, total_images: int, total_time: float):
        """Log final summary"""
        self.log_section("GENERATION SUMMARY")
        self.log(f"Total Images Generated: {total_images}")
        self.log(f"Total Time: {total_time:.2f}s")
        self.log(f"Average Time per Image: {total_time/total_images:.2f}s\n")
===./utils/__init__.py===

===./utils/supabase_client.py===
from supabase import create_client, Client
from config.settings import config
from models.data_models import SongMetadata, LyricLine
from typing import List, Optional
import requests
import json
from pathlib import Path

class SupabaseClient:
    def __init__(self):
        self.client: Client = create_client(
            config.SUPABASE_URL,
            config.SUPABASE_KEY
        )
    
    def get_song_metadata(self, song_id: str) -> SongMetadata:
        """Fetch song metadata from database"""
        response = (
            self.client.table("songs")
            .select("*")
            .eq("id", song_id)
            .single()
            .execute()
        )
        return SongMetadata(**response.data)
    
    def get_lyrics(self, song_id: str, start_line: int = 1, 
                   end_line: Optional[int] = None) -> List[LyricLine]:
        """Fetch lyrics for a song, optionally filtered by line range"""
        query = (
            self.client.table("lyrics")
            .select("*")
            .eq("song_id", song_id)
            .order("line_number")
        )
        
        if end_line:
            query = query.gte("line_number", start_line).lte("line_number", end_line)
        else:
            query = query.gte("line_number", start_line)
        
        response = query.execute()
        
        # Parse breakdown_data from JSON string to dict
        lyrics = []
        for line in response.data:
            if line.get('breakdown_data') and isinstance(line['breakdown_data'], str):
                line['breakdown_data'] = json.loads(line['breakdown_data'])
            lyrics.append(LyricLine(**line))
        
        return lyrics
    
    def get_all_lyrics_for_context(self, song_id: str) -> List[LyricLine]:
        """Fetch ALL lyrics for context understanding"""
        response = (
            self.client.table("lyrics")
            .select("*")
            .eq("song_id", song_id)
            .order("line_number")
            .execute()
        )
        
        # Parse breakdown_data from JSON string to dict
        lyrics = []
        for line in response.data:
            if line.get('breakdown_data') and isinstance(line['breakdown_data'], str):
                line['breakdown_data'] = json.loads(line['breakdown_data'])
            lyrics.append(LyricLine(**line))
        
        return lyrics
        
    def download_audio_file(self, audio_path: str, output_path: Path) -> Path:
        """Download audio file from Supabase storage"""
        base_url = config.SUPABASE_URL.rstrip('/rest/v1')
        
        # Try multiple URL patterns (the stored path might be the full path in the audio bucket)
        possible_urls = [
            f"{base_url}/storage/v1/object/public/audio/{audio_path}",
            f"{base_url}/storage/v1/object/public/{audio_path}",
            f"{base_url}/storage/v1/object/public/audio/{audio_path.replace('albums/', '')}",
        ]
        
        successful_download = False
        
        for url in possible_urls:
            try:
                print(f"  Trying: {url[:80]}...")
                response = requests.get(url, timeout=30)
                response.raise_for_status()
                
                # Success! Save the file
                output_path.parent.mkdir(parents=True, exist_ok=True)
                output_path.write_bytes(response.content)
                print(f"  ‚úì Downloaded from: {url[:80]}...")
                successful_download = True
                break
                
            except requests.exceptions.HTTPError as e:
                print(f"  ‚úó Failed with status {e.response.status_code}")
                continue
            except Exception as e:
                print(f"  ‚úó Failed: {str(e)}")
                continue
        
        if not successful_download:
            raise Exception(f"Could not download audio from any URL pattern. Path: {audio_path}")
        
        return output_path
===./utils/drive_client.py===
"""
Google Drive Client using OAuth 2.0
Handles authentication, folder creation, and file uploads
"""

from google.auth.transport.requests import Request
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload
from googleapiclient.errors import HttpError
from pathlib import Path
from typing import Optional, Dict
import os
import pickle

class DriveClient:
    # Scopes define what permissions we need
    SCOPES = ['https://www.googleapis.com/auth/drive.file']
    
    def __init__(self, credentials_path: str, root_folder_id: Optional[str] = None):
        """
        Initialize Drive client with OAuth credentials
        
        Args:
            credentials_path: Path to OAuth client secret JSON
            root_folder_id: Optional root folder ID to organize uploads
        """
        self.credentials_path = Path(credentials_path)
        self.root_folder_id = root_folder_id
        self.token_path = self.credentials_path.parent / "token.pickle"
        self.service = None
        
        self._authenticate()
    
    def _authenticate(self):
        """Handle OAuth authentication flow"""
        creds = None
        
        # Check if we have saved credentials
        if self.token_path.exists():
            print("  ‚Üí Loading saved credentials...")
            with open(self.token_path, 'rb') as token:
                creds = pickle.load(token)
        
        # If credentials are invalid or don't exist, get new ones
        if not creds or not creds.valid:
            if creds and creds.expired and creds.refresh_token:
                print("  ‚Üí Refreshing expired credentials...")
                creds.refresh(Request())
            else:
                print("  ‚Üí Starting OAuth flow (browser will open)...")
                print("  ‚Üí Please authorize the app in your browser")
                flow = InstalledAppFlow.from_client_secrets_file(
                    str(self.credentials_path), self.SCOPES
                )
                creds = flow.run_local_server(port=0)
                print("  ‚úì Authorization successful!")
            
            # Save credentials for next time
            with open(self.token_path, 'wb') as token:
                pickle.dump(creds, token)
            print(f"  ‚úì Credentials saved to {self.token_path}")
        
        # Build the Drive service
        self.service = build('drive', 'v3', credentials=creds)
        print("  ‚úì Drive client ready!")
    
    def create_folder(self, folder_name: str, parent_folder_id: Optional[str] = None) -> str:
        """
        Create a folder in Google Drive
        
        Args:
            folder_name: Name of the folder to create
            parent_folder_id: Optional parent folder ID
            
        Returns:
            Created folder ID
        """
        try:
            # Check if folder already exists
            parent_id = parent_folder_id or self.root_folder_id
            
            if parent_id:
                query = f"name='{folder_name}' and '{parent_id}' in parents and mimeType='application/vnd.google-apps.folder' and trashed=false"
            else:
                query = f"name='{folder_name}' and mimeType='application/vnd.google-apps.folder' and trashed=false"
            
            results = self.service.files().list(
                q=query,
                spaces='drive',
                fields='files(id, name)'
            ).execute()
            
            files = results.get('files', [])
            
            if files:
                print(f"  ‚Üí Folder '{folder_name}' already exists")
                return files[0]['id']
            
            # Create new folder
            file_metadata = {
                'name': folder_name,
                'mimeType': 'application/vnd.google-apps.folder'
            }
            
            if parent_id:
                file_metadata['parents'] = [parent_id]
            
            folder = self.service.files().create(
                body=file_metadata,
                fields='id, webViewLink'
            ).execute()
            
            folder_id = folder.get('id')
            print(f"  ‚úì Created folder: {folder_name} (ID: {folder_id})")
            
            return folder_id
            
        except HttpError as error:
            print(f"  ‚ùå Error creating folder: {error}")
            raise
    
    def upload_file(self, 
                   file_path: Path, 
                   folder_id: Optional[str] = None,
                   make_public: bool = False) -> Dict[str, str]:
        """
        Upload a file to Google Drive
        
        Args:
            file_path: Path to the file to upload
            folder_id: Optional folder ID to upload to
            make_public: Whether to make the file publicly accessible
            
        Returns:
            Dictionary with file_id, web_view_link, and download_link
        """
        try:
            if not file_path.exists():
                raise FileNotFoundError(f"File not found: {file_path}")
            
            file_name = file_path.name
            mime_type = self._get_mime_type(file_path)
            
            file_metadata = {'name': file_name}
            
            if folder_id:
                file_metadata['parents'] = [folder_id]
            elif self.root_folder_id:
                file_metadata['parents'] = [self.root_folder_id]
            
            media = MediaFileUpload(
                str(file_path),
                mimetype=mime_type,
                resumable=True
            )
            
            print(f"  ‚Üí Uploading {file_name} ({file_path.stat().st_size / (1024*1024):.2f} MB)...")
            
            file = self.service.files().create(
                body=file_metadata,
                media_body=media,
                fields='id, webViewLink, webContentLink'
            ).execute()
            
            file_id = file.get('id')
            web_view_link = file.get('webViewLink')
            
            print(f"  ‚úì Upload complete! File ID: {file_id}")
            
            # Make public if requested
            if make_public:
                self._make_file_public(file_id)
                download_link = f"https://drive.google.com/uc?export=download&id={file_id}"
            else:
                download_link = file.get('webContentLink', web_view_link)
            
            return {
                'file_id': file_id,
                'web_view_link': web_view_link,
                'download_link': download_link,
                'folder_id': folder_id
            }
            
        except HttpError as error:
            print(f"  ‚ùå Upload error: {error}")
            raise
    
    def _make_file_public(self, file_id: str):
        """Make a file publicly accessible"""
        try:
            self.service.permissions().create(
                fileId=file_id,
                body={
                    'type': 'anyone',
                    'role': 'reader'
                }
            ).execute()
            print(f"  ‚úì File made public")
        except HttpError as error:
            print(f"  ‚ö†Ô∏è  Could not make file public: {error}")
    
    def _get_mime_type(self, file_path: Path) -> str:
        """Get MIME type based on file extension"""
        extension = file_path.suffix.lower()
        mime_types = {
            '.mp4': 'video/mp4',
            '.json': 'application/json',
            '.txt': 'text/plain',
            '.jpg': 'image/jpeg',
            '.jpeg': 'image/jpeg',
            '.png': 'image/png',
            '.mp3': 'audio/mpeg',
        }
        return mime_types.get(extension, 'application/octet-stream')
    
    def delete_file(self, file_id: str):
        """Delete a file from Drive"""
        try:
            self.service.files().delete(fileId=file_id).execute()
            print(f"  ‚úì Deleted file: {file_id}")
        except HttpError as error:
            print(f"  ‚ùå Delete error: {error}")
            raise
    
    def get_file_info(self, file_id: str) -> Dict:
        """Get information about a file"""
        try:
            file = self.service.files().get(
                fileId=file_id,
                fields='id, name, mimeType, size, webViewLink, createdTime'
            ).execute()
            return file
        except HttpError as error:
            print(f"  ‚ùå Error getting file info: {error}")
            raise
===./utils/claude_client.py===
from anthropic import Anthropic
from config.settings import config
import json
import re
from typing import List

class ClaudeClient:
    def __init__(self):
        self.client = Anthropic(api_key=config.ANTHROPIC_API_KEY)
        self.model = "claude-sonnet-4-5"
    
    def _extract_json(self, text: str) -> dict:
        """Extract JSON from Claude's response, handling markdown code blocks"""
        try:
            return json.loads(text)
        except json.JSONDecodeError:
            pass
        
        json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', text, re.DOTALL)
        if json_match:
            try:
                return json.loads(json_match.group(1))
            except json.JSONDecodeError:
                pass
        
        json_match = re.search(r'\{.*\}', text, re.DOTALL)
        if json_match:
            try:
                return json.loads(json_match.group(0))
            except json.JSONDecodeError:
                pass
        
        raise ValueError(f"Could not extract JSON from response: {text[:200]}")
    
    def create_style_guide(self, song_metadata: dict, 
                          all_lyrics: str, target_lyrics: str) -> dict:
        """Generate initial style guide and story concept"""
        prompt = f"""You're creating a lyric video for a Korean learning song.

Full song context:
{all_lyrics}

Target segment we're generating:
{target_lyrics}

Song description: {song_metadata.get('description', 'N/A')}

Analyze the lyrics:
1. Is this a conversation between two people, or a solo narrative?
2. What's happening in this segment? (brief story summary)

FIXED VISUAL STYLE:
You must use high-quality Korean webtoon art style with these characteristics:
- Clean digital illustration with smooth linework
- Soft, natural color palette (pastels, warm tones, muted colors)
- Expressive faces with detailed eyes
- Modern, trendy fashion
- Atmospheric lighting and subtle gradients
- Professional webtoon quality (think Lezhin, Naver Webtoon premium series)

IMPORTANT RULES:
- If this is a CONVERSATION (lyrics use "you/your", questions/responses between people):
  ‚Üí Must feature TWO characters of OPPOSITE SEX (one male, one female)
- Characters should be placed in WEBTOON ENVIRONMENTS (cafe, park, street, room)
- NO abstract colored backgrounds or gradient backgrounds
- NO split-screen compositions

Respond in JSON format:
{{
  "visual_style": "High-quality Korean webtoon style with clean digital illustration, soft natural colors, expressive faces, modern fashion, atmospheric lighting",
  "segment_story": "brief narrative including character genders if conversation",
  "is_conversation": true or false
}}

Note: visual_style field should always contain the exact text above for consistency.
"""
        
        response = self.client.messages.create(
            model=self.model,
            max_tokens=1000,
            messages=[{"role": "user", "content": prompt}]
        )
        
        return self._extract_json(response.content[0].text)
    
    def generate_character_design(self, style_guide: dict, gender: str) -> str:
        """Generate a character design portrait for reference"""
        
        prompt = f"""High-quality Korean webtoon style
    - No background
    - The face should appear natural, without glittering or sparkling effects.
    - Professional webtoon quality 

    Story context: {style_guide['segment_story']}

    Create a CHARACTER DESIGN PORTRAIT for a {gender} character in this webtoon style.

    This is a REFERENCE IMAGE for character consistency across scenes.

    REQUIREMENTS:
    - Young {gender} character (early 20s)
    - Character fills most of frame (shoulders and head visible)
    - Character facing forward or slightly angled (3/4 view)
    - Friendly, approachable expression
    - Clear features: face, hair, clothing details
    - Webtoon-quality rendering: smooth shading, clean lines, professional finish

    FORBIDDEN:
    - NO text

    Image specs: 1080x1080 pixels

    Respond with ONLY the Seedream prompt for this {gender} character in high-quality webtoon style.
    """
        
        response = self.client.messages.create(
            model=self.model,
            max_tokens=1000,
            messages=[{"role": "user", "content": prompt}]
        )
        
        return response.content[0].text.strip()
    
    def generate_first_prompt(self, lyric_line: dict, style_guide: dict, 
                             character_design_prompts: List[str]) -> str:
        """Generate prompt for the first image"""
        
        is_conversation = style_guide.get('is_conversation', True)
        
        if is_conversation:
            character_rule = "- Show TWO characters (male and female from the reference portraits)"
        else:
            character_rule = "- Show the character from the reference portrait"
        
        prompt = f"""Visual style: {style_guide['visual_style']}
Story context: {style_guide['segment_story']}

First lyric line: "{lyric_line['english_text']} / {lyric_line['korean_text']}"

CHARACTER REFERENCE INFORMATION:
You will receive reference portrait images. Here are the exact prompts used to create them:

Male character prompt:
{character_design_prompts[0]}

Female character prompt:
{character_design_prompts[1]}

These references show what the characters LOOK LIKE (facial features, hair, outfits, style).
Your job is to create a SCENE using these exact same characters.

Create an opening scene focused on the CHARACTERS in a WEBTOON ENVIRONMENT.

CHARACTER RULES:
{character_rule}
- Characters should look EXACTLY as described in the reference prompts above
- SAME outfits, SAME hairstyles, SAME features
- Characters should fill significant frame space
- People are the primary focus

ENVIRONMENT RULES:
- Must be a WEBTOON PLACE: cafe interior, park, street, room, etc with details
- NO solid color backgrounds
- NO abstract gradient backgrounds
- Background should feel like an actual location

COMPOSITION RULES:
- NO split-screen compositions
- NO divider lines between characters
- Characters in the SAME unified space
- Single cohesive scene

FORBIDDEN:
- NO text overlays
- DO NOT change character appearance from references

Image specs: 1080x1080 pixels (square format)

Respond with ONLY the Seedream prompt.
"""
        
        response = self.client.messages.create(
            model=self.model,
            max_tokens=1000,
            messages=[{"role": "user", "content": prompt}]
        )
        
        return response.content[0].text.strip()
    
    def generate_next_prompt(self, previous_prompts: List[str], 
                            current_lyric: dict, 
                            style_guide: dict,
                            character_design_prompts: List[str],
                            line_number: int,
                            total_lines: int) -> dict:
        """Generate prompt for subsequent images"""
        
        prompts_history = "\n".join([
            f"Image {i+1}: {prompt[:120]}..."
            for i, prompt in enumerate(previous_prompts)
        ])
        
        is_conversation = style_guide.get('is_conversation', True)
        
        prompt = f"""You're creating image #{line_number} of {total_lines} in a cinematic sequence.

STORY CONTEXT: {style_guide['segment_story']}

ALL PREVIOUS SCENE PROMPTS:
{prompts_history}

Current lyric: "{current_lyric['english_text']} / {current_lyric['korean_text']}"
Visual style: {style_guide['visual_style']}

CHARACTER REFERENCE INFORMATION:
You will receive reference portrait images. Here are the exact prompts used to create them:

Male character prompt:
{character_design_prompts[0]}

Female character prompt:
{character_design_prompts[1]}

These references show what the characters LOOK LIKE (facial features, hair, outfits, style).
Use these EXACT character descriptions in your scene.

YOUR JOB:
Create a NEW SCENE for this lyric using those same characters with their exact appearance.

SCENE REQUIREMENTS:
- Place characters in a WEBTOON ENVIRONMENT (cafe, park, street, room with details)
- Characters should look EXACTLY as described in the reference prompts
- SAME outfits, SAME hairstyles, SAME features
- Characters should fill significant frame space
- NO abstract/solid color backgrounds
- NO split-screen or divided compositions
- NO divider lines between characters
- Characters in unified space

SCENE CONTINUITY:
{'- Keep both characters present (ongoing conversation)' if is_conversation else ''}
- If lyric says "you/your" ‚Üí other person must be visible
- Scene can change naturally if lyric suggests it

CRITICAL: VISUAL VARIETY
Look at previous scenes. Make this one DISTINCTLY DIFFERENT:
- Different camera work
- Different character positions/interactions
- Different character gestures/face expressions
- Different framing
- NOT just expression changes or slight variations

Think about how the scene composition, character arrangement, and perspective can tell the story differently.

FORBIDDEN:
- NO text
- DO NOT change character appearance (outfits, hair, features)

IMPORTANT: Characters should not look at the viewer. Instead, they must direct their gaze toward each other, toward objects in the environment, toward what they are gesturing at, etc.

Respond in JSON:
{{
  "creative_reasoning": "How is this scene different from previous ones?",
  "seedream_prompt": "Describe the scene with characters matching the exact reference descriptions",
  "use_previous_as_reference": true
}}
"""
        
        response = self.client.messages.create(
            model=self.model,
            max_tokens=1000,
            messages=[{"role": "user", "content": prompt}]
        )
        
        return self._extract_json(response.content[0].text)
===./models/__init__.py===

===./models/data_models.py===
from pydantic import BaseModel
from typing import Optional, List
from datetime import datetime

class LyricLine(BaseModel):
    id: str
    song_id: str
    line_number: int
    english_text: str
    korean_text: str
    start_time_seconds: float
    end_time_seconds: float
    voice_over_file_path: Optional[str]
    breakdown_data: Optional[dict]
    is_published: bool

class SongMetadata(BaseModel):
    id: str
    title: str
    artist: Optional[str] = None
    description: Optional[str]
    audio_file_path: str
    duration_seconds: Optional[float] = None
    artist_gender: Optional[str]
    original_lyrics_text: Optional[str]
    cover_image_prompt: Optional[str]

class CustomCreativeInput(BaseModel):
    """Optional custom input to override auto-generation"""
    story_description: Optional[str] = None  # Custom story narrative
    character_male_description: Optional[str] = None  # Custom male character
    character_female_description: Optional[str] = None  # Custom female character
    is_conversation: Optional[bool] = None  # Override conversation detection

class StyleGuide(BaseModel):
    visual_style: str
    segment_story: str
    is_conversation: bool = True 

class ImagePromptDecision(BaseModel):
    line_number: int
    creative_reasoning: str
    seedream_prompt: str
    use_previous_as_reference: bool

class GeneratedImage(BaseModel):
    line_number: int
    image_path: str
    prompt_used: str
    start_time: float
    end_time: float
    used_reference: bool
    reference_image: Optional[str] = None
    generation_time: Optional[float] = None

class VideoGenerationRequest(BaseModel):
    song_id: str
    start_line: int = 1
    end_line: Optional[int] = None
    resolution: str = "4k"
    output_filename: Optional[str] = None
    custom_input: Optional[CustomCreativeInput] = None
===./test.py===
# test_complete_pipeline.py
"""
Complete test script for lyric video generator
Tests all components with detailed logging
"""

import os
import sys
from pathlib import Path
import traceback
from datetime import datetime

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent))

def log(message, level="INFO"):
    """Pretty logging with timestamps"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    symbols = {
        "INFO": "‚ÑπÔ∏è ",
        "SUCCESS": "‚úÖ",
        "ERROR": "‚ùå",
        "WARNING": "‚ö†Ô∏è ",
        "TEST": "üß™"
    }
    symbol = symbols.get(level, "  ")
    print(f"[{timestamp}] {symbol} {message}")

def test_environment():
    """Test environment variables"""
    log("Testing environment variables...", "TEST")

    from config.settings import config
    
    required_vars = [
        "SUPABASE_URL",
        "SUPABASE_KEY", 
        "ANTHROPIC_API_KEY",
        "SEEDREAM_API_KEY",
        "SEEDREAM_ENDPOINT"
    ]
    
    missing = []
    for var in required_vars:
        value = os.getenv(var)
        if not value:
            missing.append(var)
            log(f"Missing: {var}", "ERROR")
        else:
            masked = value[:10] + "..." if len(value) > 10 else value
            log(f"Found: {var} = {masked}", "SUCCESS")
    
    if missing:
        log(f"Missing environment variables: {', '.join(missing)}", "ERROR")
        return False
    
    log("All environment variables present", "SUCCESS")
    return True

def test_dependencies():
    """Test required packages"""
    log("Testing Python dependencies...", "TEST")
    
    required_packages = {
        "supabase": "supabase",
        "anthropic": "anthropic",
        "requests": "requests",
        "moviepy.editor": "moviepy",
        "PIL": "pillow",
        "pydantic": "pydantic",
        "dotenv": "python-dotenv",
        "tqdm": "tqdm",
        "korean_romanizer.romanizer": "korean-romanizer"
    }
    
    missing = []
    for import_name, package_name in required_packages.items():
        try:
            __import__(import_name)
            log(f"Found: {package_name}", "SUCCESS")
        except ImportError as e:
            missing.append(package_name)
            log(f"Missing: {package_name} - {str(e)}", "ERROR")
    
    if missing:
        log(f"Install missing packages: pip install {' '.join(missing)}", "ERROR")
        return False
    
    log("All dependencies installed", "SUCCESS")
    return True

def test_project_structure():
    """Test project directories and files"""
    log("Testing project structure...", "TEST")
    
    base_dir = Path(__file__).parent
    
    required_dirs = [
        "config",
        "agents", 
        "utils",
        "models",
        "output",
        "fonts"
    ]
    
    required_files = [
        "config/__init__.py",
        "config/settings.py",
        "agents/__init__.py",
        "agents/data_retriever.py",
        "agents/style_planner.py",
        "agents/image_director.py",
        "agents/video_compositor.py",
        "utils/__init__.py",
        "utils/supabase_client.py",
        "utils/claude_client.py",
        "utils/seedream_client.py",
        "utils/text_utils.py",
        "models/__init__.py",
        "models/data_models.py",
        "main.py",
        "fonts/MaruBuri-Bold.ttf"
    ]
    
    all_good = True
    
    for dir_name in required_dirs:
        dir_path = base_dir / dir_name
        if dir_path.exists():
            log(f"Directory exists: {dir_name}", "SUCCESS")
        else:
            log(f"Directory missing: {dir_name}", "ERROR")
            all_good = False
    
    for file_name in required_files:
        file_path = base_dir / file_name
        if file_path.exists():
            log(f"File exists: {file_name}", "SUCCESS")
        else:
            log(f"File missing: {file_name}", "ERROR")
            all_good = False
    
    return all_good

def test_imports():
    """Test importing project modules"""
    log("Testing project imports...", "TEST")
    
    try:
        from config.settings import config
        log(f"Config imported - Base dir: {config.BASE_DIR}", "SUCCESS")
        
        from utils.supabase_client import SupabaseClient
        log("SupabaseClient imported", "SUCCESS")
        
        from utils.claude_client import ClaudeClient
        log("ClaudeClient imported", "SUCCESS")
        
        from utils.seedream_client import SeedreamClient
        log("SeedreamClient imported", "SUCCESS")
        
        from utils.text_utils import korean_to_romanization
        log("Text utils imported", "SUCCESS")
        
        from models.data_models import VideoGenerationRequest
        log("Data models imported", "SUCCESS")
        
        from agents.data_retriever import DataRetriever
        log("DataRetriever imported", "SUCCESS")
        
        return True
        
    except Exception as e:
        log(f"Import error: {str(e)}", "ERROR")
        traceback.print_exc()
        return False

def test_supabase():
    """Test Supabase connection"""
    log("Testing Supabase connection...", "TEST")
    
    try:
        from utils.supabase_client import SupabaseClient
        
        client = SupabaseClient()
        log("Supabase client created", "SUCCESS")
        
        # Test fetching a song
        test_song_id = "8e36b8ba-a752-4717-8f55-78f1d4996c8c"
        song = client.get_song_metadata(test_song_id)
        log(f"Fetched song: '{song.title}' by {song.artist}", "SUCCESS")
        log(f"  Duration: {song.duration_seconds}s", "INFO")
        log(f"  Audio path: {song.audio_file_path}", "INFO")
        
        # Test fetching lyrics
        lyrics = client.get_lyrics(test_song_id, start_line=1, end_line=3)
        log(f"Fetched {len(lyrics)} lyric lines", "SUCCESS")
        for lyric in lyrics:
            log(f"  Line {lyric.line_number}: {lyric.english_text[:30]}...", "INFO")
        
        return True
        
    except Exception as e:
        log(f"Supabase error: {str(e)}", "ERROR")
        traceback.print_exc()
        return False

def test_claude():
    """Test Claude API"""
    log("Testing Claude API...", "TEST")
    
    try:
        from utils.claude_client import ClaudeClient
        
        client = ClaudeClient()
        log("Claude client created", "SUCCESS")
        
        # Simple test call
        response = client.client.messages.create(
            model="claude-sonnet-4-5",
            max_tokens=100,
            messages=[{
                "role": "user",
                "content": "Respond with exactly: 'API test successful'"
            }]
        )
        
        result = response.content[0].text
        log(f"Claude response: {result}", "SUCCESS")
        log(f"  Tokens used: {response.usage.input_tokens} in, {response.usage.output_tokens} out", "INFO")
        
        return True
        
    except Exception as e:
        log(f"Claude API error: {str(e)}", "ERROR")
        traceback.print_exc()
        return False

def test_seedream():
    """Test Seedream API"""
    log("Testing Seedream API...", "TEST")
    
    try:
        from utils.seedream_client import SeedreamClient
        from config.settings import config
        
        client = SeedreamClient()
        log("Seedream client created", "SUCCESS")
        
        # Simple test generation
        log("Generating test image (this takes ~3-5 seconds)...", "INFO")
        result = client.generate_image(
            prompt="a simple red apple on a white table, minimal, clean",
            size="1080x1080"
        )
        
        if result.get('data') and len(result['data']) > 0:
            image_url = result['data'][0]['url']
            log(f"Image generated successfully", "SUCCESS")
            log(f"  URL: {image_url[:60]}...", "INFO")
            
            # Try to download it
            test_path = config.TEMP_DIR / "test_image.jpg"
            test_path.parent.mkdir(parents=True, exist_ok=True)
            downloaded = client.download_image(image_url, test_path)
            log(f"Image downloaded to: {downloaded}", "SUCCESS")
            log(f"  File size: {downloaded.stat().st_size / 1024:.1f} KB", "INFO")
            
            return True
        else:
            log(f"Unexpected response format: {result}", "ERROR")
            return False
        
    except Exception as e:
        log(f"Seedream API error: {str(e)}", "ERROR")
        traceback.print_exc()
        return False

def test_romanization():
    """Test Korean romanization"""
    log("Testing Korean romanization...", "TEST")
    
    try:
        from utils.text_utils import korean_to_romanization
        
        test_cases = [
            ("ÏïàÎÖïÌïòÏÑ∏Ïöî", "annyeonghaseyo"),
            ("ÎèÑÏôÄÏ£ºÏÑ∏Ïöî", "dowajuseyo"),
            ("Í∞êÏÇ¨Ìï©ÎãàÎã§", "gamsahamnida")
        ]
        
        all_good = True
        for korean, expected in test_cases:
            result = korean_to_romanization(korean)
            if result.lower() == expected.lower():
                log(f"'{korean}' ‚Üí '{result}' ‚úì", "SUCCESS")
            else:
                log(f"'{korean}' ‚Üí '{result}' (expected: {expected})", "WARNING")
                all_good = False
        
        return all_good
        
    except Exception as e:
        log(f"Romanization error: {str(e)}", "ERROR")
        traceback.print_exc()
        return False

def test_font():
    """Test font rendering"""
    log("Testing font rendering...", "TEST")
    
    try:
        from PIL import Image, ImageDraw, ImageFont
        from config.settings import config
        
        if not config.FONT_PATH.exists():
            log(f"Font file not found: {config.FONT_PATH}", "ERROR")
            return False
        
        log(f"Font file found: {config.FONT_PATH}", "SUCCESS")
        
        # Try to load font
        font = ImageFont.truetype(str(config.FONT_PATH), 48)
        log("Font loaded successfully", "SUCCESS")
        
        # Test rendering Korean text
        img = Image.new('RGB', (500, 100), color='black')
        draw = ImageDraw.Draw(img)
        test_text = "ÏïàÎÖïÌïòÏÑ∏Ïöî Hello"
        draw.text((10, 10), test_text, font=font, fill='white')
        
        # Save test image
        test_path = config.TEMP_DIR / "test_font.png"
        test_path.parent.mkdir(parents=True, exist_ok=True)
        img.save(test_path)
        log(f"Test image saved: {test_path}", "SUCCESS")
        
        return True
        
    except Exception as e:
        log(f"Font error: {str(e)}", "ERROR")
        traceback.print_exc()
        return False

def test_minimal_pipeline():
    """Run a minimal end-to-end test with 1 line"""
    log("Testing minimal pipeline (1 line)...", "TEST")
    log("This will take ~30-60 seconds due to API calls", "INFO")
    
    try:
        from main import generate_lyric_video
        from config.settings import config
        
        # Generate just line 1
        test_song_id = "8e36b8ba-a752-4717-8f55-78f1d4996c8c"
        
        result = generate_lyric_video(
            song_id=test_song_id,
            start_line=1,
            end_line=1
        )
        
        if result.exists():
            file_size = result.stat().st_size / (1024 * 1024)  # MB
            log(f"Video created: {result}", "SUCCESS")
            log(f"  File size: {file_size:.2f} MB", "INFO")
            return True
        else:
            log("Video file not created", "ERROR")
            return False
        
    except Exception as e:
        log(f"Pipeline error: {str(e)}", "ERROR")
        traceback.print_exc()
        return False

def main():
    """Run all tests"""
    print("\n" + "="*80)
    print("LYRIC VIDEO GENERATOR - COMPLETE SYSTEM TEST")
    print("="*80 + "\n")
    
    results = {}
    
    # Run tests
    tests = [
        ("Environment Variables", test_environment),
        ("Python Dependencies", test_dependencies),
        ("Project Structure", test_project_structure),
        ("Module Imports", test_imports),
        ("Supabase Connection", test_supabase),
        ("Claude API", test_claude),
        ("Seedream API", test_seedream),
        ("Korean Romanization", test_romanization),
        ("Font Rendering", test_font),
    ]
    
    for test_name, test_func in tests:
        print(f"\n{'‚îÄ'*80}")
        try:
            results[test_name] = test_func()
        except Exception as e:
            log(f"Unexpected error in {test_name}: {str(e)}", "ERROR")
            results[test_name] = False
        print()
    
    # Summary
    print("\n" + "="*80)
    print("TEST SUMMARY")
    print("="*80)
    
    passed = sum(1 for v in results.values() if v)
    total = len(results)
    
    for test_name, result in results.items():
        status = "‚úÖ PASS" if result else "‚ùå FAIL"
        print(f"{status} - {test_name}")
    
    print(f"\nTotal: {passed}/{total} tests passed")
    
    # Decide if we should run minimal pipeline
    critical_tests = [
        "Environment Variables",
        "Python Dependencies", 
        "Module Imports",
        "Supabase Connection",
        "Claude API",
        "Seedream API"
    ]
    
    critical_passed = all(results.get(t, False) for t in critical_tests)
    
    if critical_passed:
        print("\n" + "="*80)
        print("All critical tests passed! Running minimal pipeline test...")
        print("="*80 + "\n")
        
        pipeline_result = test_minimal_pipeline()
        
        if pipeline_result:
            print("\n" + "="*80)
            print("üéâ ALL TESTS PASSED - SYSTEM READY!")
            print("="*80)
        else:
            print("\n" + "="*80)
            print("‚ö†Ô∏è  Pipeline test failed - check logs above")
            print("="*80)
    else:
        print("\n" + "="*80)
        print("‚ùå Critical tests failed - fix issues before running pipeline")
        print("="*80)
        
        print("\nFailed critical tests:")
        for test in critical_tests:
            if not results.get(test, False):
                print(f"  - {test}")

if __name__ == "__main__":
    main()
===./create_video.py===
"""
assemble_video.py
Simple script to assemble video from already-generated images
Usage: python assemble_video.py
"""

from agents.data_retriever import DataRetriever
from agents.video_compositor import VideoCompositor
from models.data_models import VideoGenerationRequest, GeneratedImage, LyricLine
from config.settings import config
from pathlib import Path
from typing import List
import json

def find_existing_images(song_id: str, start_line: int, end_line: int, 
                        lyrics: List[LyricLine]) -> List[GeneratedImage]:
    """Find already-generated images for the given line range"""
    frames_dir = config.FRAMES_DIR / song_id
    
    if not frames_dir.exists():
        raise FileNotFoundError(f"Frames directory not found: {frames_dir}")
    
    images = []
    missing_lines = []
    
    for lyric in lyrics:
        image_filename = f"line_{lyric.line_number:03d}.jpg"
        image_path = frames_dir / image_filename
        
        if not image_path.exists():
            missing_lines.append(lyric.line_number)
            continue
        
        images.append(GeneratedImage(
            line_number=lyric.line_number,
            image_path=str(image_path),
            prompt_used="N/A - using existing image",
            start_time=lyric.start_time_seconds,
            end_time=lyric.end_time_seconds,
            used_reference=True,
            reference_image=None
        ))
    
    if missing_lines:
        raise FileNotFoundError(
            f"Missing images for lines: {missing_lines}\n"
            f"Expected location: {frames_dir}\n"
            f"Generate these images first before assembling video."
        )
    
    return images

def assemble_from_existing_images(song_id: str, 
                                  start_line: int = 1, 
                                  end_line: int = None) -> Path:
    """
    Assemble video from already-generated images
    
    Args:
        song_id: Song ID from database
        start_line: Starting lyric line number
        end_line: Ending lyric line number (None = last line)
        
    Returns:
        Path to generated video file
    """
    print("=" * 60)
    print("üé¨ VIDEO ASSEMBLY (FROM EXISTING IMAGES)")
    print("=" * 60)
    
    # Create necessary directories
    config.create_directories()
    
    # Create request
    request = VideoGenerationRequest(
        song_id=song_id,
        start_line=start_line,
        end_line=end_line
    )
    
    # Step 1: Fetch data (audio + lyrics only)
    print("\nüì• STEP 1: Fetching data from Supabase...")
    retriever = DataRetriever()
    song, all_lyrics, target_lyrics, audio_path = retriever.fetch_all_data(request)
    print(f"‚úì Song: {song.title} by {song.artist}")
    print(f"‚úì Lines {start_line} to {target_lyrics[-1].line_number}")
    print(f"‚úì Total lines: {len(target_lyrics)}")
    
    # Step 2: Find existing images
    print("\nüñºÔ∏è  STEP 2: Loading existing images...")
    images = find_existing_images(song_id, start_line, target_lyrics[-1].line_number, target_lyrics)
    print(f"‚úì Found {len(images)} existing images")
    for img in images:
        print(f"  - Line {img.line_number}: {Path(img.image_path).name}")
    
    # Step 3: Assemble video
    print("\nüé¨ STEP 3: Assembling video...")
    compositor = VideoCompositor()
    
    output_filename = f"song_{song_id}_lines_{start_line}-{target_lyrics[-1].line_number}.mp4"
    output_path = config.VIDEOS_DIR / output_filename
    
    final_video = compositor.assemble_video(images, target_lyrics, audio_path, output_path)
    
    # Save metadata
    metadata = {
        "song_id": song_id,
        "title": song.title,
        "artist": song.artist,
        "start_line": start_line,
        "end_line": target_lyrics[-1].line_number,
        "total_images": len(images),
        "assembled_from_existing": True,
        "images": [img.dict() for img in images]
    }
    
    metadata_path = config.VIDEOS_DIR / f"{output_filename}.json"
    metadata_path.write_text(json.dumps(metadata, indent=2))
    
    print("\n" + "=" * 60)
    print("‚úÖ VIDEO ASSEMBLY COMPLETE!")
    print(f"üìπ Video: {final_video}")
    print(f"üìÑ Metadata: {metadata_path}")
    print("=" * 60)
    
    return final_video

if __name__ == "__main__":
    # Edit these values:
    SONG_ID = "5bda393c-4fb0-43a5-bb47-9f23bba063b2"  # Your song ID
    START_LINE = 1
    END_LINE = 8  # Or None for all lines
    
    try:
        assemble_from_existing_images(
            song_id=SONG_ID,
            start_line=START_LINE,
            end_line=END_LINE
        )
    except FileNotFoundError as e:
        print(f"\n‚ùå ERROR: {e}")
        print("\nMake sure images exist at:")
        print(f"  {config.FRAMES_DIR / SONG_ID}/")
        print("\nExpected files:")
        for i in range(START_LINE, (END_LINE or START_LINE) + 1):
            print(f"  - line_{i:03d}.jpg")
    except Exception as e:
        print(f"\n‚ùå UNEXPECTED ERROR: {e}")
        import traceback
        traceback.print_exc()
===./test_drive_oauth.py===
"""
Test OAuth authentication with Google Drive
Run this to verify your setup works before integrating
"""

import sys
from pathlib import Path
from dotenv import load_dotenv
import os

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent))

load_dotenv()

from utils.drive_client import DriveClient

def test_drive_oauth():
    """Test OAuth flow and Drive operations"""
    
    print("=" * 60)
    print("üîê GOOGLE DRIVE OAUTH TEST")
    print("=" * 60)
    
    # Get credentials from .env
    credentials_path = os.getenv('GOOGLE_DRIVE_CREDENTIALS_PATH')
    root_folder_id = os.getenv('GOOGLE_DRIVE_ROOT_FOLDER_ID')
    
    if not credentials_path:
        print("‚ùå ERROR: GOOGLE_DRIVE_CREDENTIALS_PATH not set in .env")
        return False
    
    credentials_path = Path(credentials_path)
    if not credentials_path.exists():
        print(f"‚ùå ERROR: Credentials file not found: {credentials_path}")
        print(f"   Looking at: {credentials_path.absolute()}")
        return False
    
    print(f"\n‚úì Credentials file: {credentials_path}")
    print(f"‚úì Root folder ID: {root_folder_id or 'None (will upload to My Drive)'}")
    
    # Step 1: Authenticate
    print("\n" + "‚îÄ" * 60)
    print("üìã Step 1: Authenticating with OAuth...")
    print("‚îÄ" * 60)
    
    try:
        client = DriveClient(
            credentials_path=str(credentials_path),
            root_folder_id=root_folder_id
        )
        print("\n‚úÖ Authentication successful!")
    except Exception as e:
        print(f"\n‚ùå Authentication failed: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # Step 2: Create a test folder
    print("\n" + "‚îÄ" * 60)
    print("üìÅ Step 2: Creating test folder...")
    print("‚îÄ" * 60)
    
    try:
        test_folder_id = client.create_folder("Melos_OAuth_Test")
        print(f"‚úÖ Test folder created/found: {test_folder_id}")
    except Exception as e:
        print(f"‚ùå Folder creation failed: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # Step 3: Create and upload a test file
    print("\n" + "‚îÄ" * 60)
    print("üì§ Step 3: Uploading test file...")
    print("‚îÄ" * 60)
    
    try:
        # Create a small test file
        test_file = Path("/tmp/melos_test.txt")
        test_file.write_text("This is a test file from Melos Video Uploader!\nOAuth is working! üéâ")
        
        result = client.upload_file(
            file_path=test_file,
            folder_id=test_folder_id,
            make_public=False
        )
        
        print(f"\n‚úÖ Upload successful!")
        print(f"  üìÑ File ID: {result['file_id']}")
        print(f"  üîó View Link: {result['web_view_link']}")
        
        # Cleanup test file
        test_file.unlink()
        
    except Exception as e:
        print(f"‚ùå Upload failed: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # Step 4: Get file info
    print("\n" + "‚îÄ" * 60)
    print("‚ÑπÔ∏è  Step 4: Verifying upload...")
    print("‚îÄ" * 60)
    
    try:
        file_info = client.get_file_info(result['file_id'])
        print(f"‚úÖ File verified in Drive:")
        print(f"  Name: {file_info['name']}")
        print(f"  Size: {file_info.get('size', 'N/A')} bytes")
        print(f"  Created: {file_info['createdTime']}")
    except Exception as e:
        print(f"‚ùå Verification failed: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # Success!
    print("\n" + "=" * 60)
    print("üéâ ALL TESTS PASSED!")
    print("=" * 60)
    print("\n‚úì OAuth authentication works")
    print("‚úì Folder creation works")
    print("‚úì File upload works")
    print("‚úì File verification works")
    print("\nüìÅ Test folder in Drive: Melos_OAuth_Test")
    print("üîó Check it out:", result['web_view_link'])
    print("\n‚úÖ Ready to integrate with video generator!")
    
    return True

if __name__ == "__main__":
    success = test_drive_oauth()
    sys.exit(0 if success else 1)
===./main.py===
from agents.data_retriever import DataRetriever
from agents.style_planner import StylePlanner
from agents.image_director import ImageDirector
from agents.video_compositor import VideoCompositor
from agents.drive_uploader import DriveUploader
from models.data_models import VideoGenerationRequest, CustomCreativeInput
from config.settings import config
from pathlib import Path
from typing import Optional
import json

def generate_lyric_video(song_id: str, 
                        start_line: int = 1, 
                        end_line: Optional[int] = None,
                        custom_story: Optional[str] = None,
                        custom_male_character: Optional[str] = None,
                        custom_female_character: Optional[str] = None,
                        is_conversation: Optional[bool] = None,
                        upload_to_drive: bool = False,
                        delete_after_upload: bool = True) -> Path:
    """
    Main orchestration function for generating lyric videos
    
    Args:
        song_id: Song ID from database
        start_line: Starting lyric line number
        end_line: Ending lyric line number (None = last line)
        custom_story: Optional custom story description to override auto-generation
        custom_male_character: Optional custom male character description
        custom_female_character: Optional custom female character description
        is_conversation: Optional override for conversation detection
        upload_to_drive: Whether to upload video to Google Drive
        delete_after_upload: Whether to delete local video after upload (only if upload_to_drive=True)
        
    Returns:
        Path to generated video file
        
    Examples:
        # Fully automatic
        generate_lyric_video("song-id", 1, 10)
        
        # Custom story only
        generate_lyric_video(
            "song-id", 1, 10,
            custom_story="Two friends meeting at a cafe"
        )
        
        # Upload to Drive and delete local copy
        generate_lyric_video(
            "song-id", 1, 10,
            upload_to_drive=True,
            delete_after_upload=True
        )
        
        # Upload to Drive but keep local copy
        generate_lyric_video(
            "song-id", 1, 10,
            upload_to_drive=True,
            delete_after_upload=False
        )
    """
    print("=" * 60)
    print("üéµ LYRIC VIDEO GENERATOR")
    print("=" * 60)
    
    # Create necessary directories
    config.create_directories()
    
    # Build custom input if any provided
    custom_input = None
    if any([custom_story, custom_male_character, custom_female_character, is_conversation is not None]):
        custom_input = CustomCreativeInput(
            story_description=custom_story,
            character_male_description=custom_male_character,
            character_female_description=custom_female_character,
            is_conversation=is_conversation
        )
        print("\nüé® CUSTOM INPUT PROVIDED:")
        if custom_story:
            print(f"  üìñ Story: {custom_story[:80]}...")
        if custom_male_character:
            print(f"  üë® Male Character: {custom_male_character[:80]}...")
        if custom_female_character:
            print(f"  üë© Female Character: {custom_female_character[:80]}...")
        if is_conversation is not None:
            print(f"  üí¨ Is Conversation: {is_conversation}")
    
    # Create request
    request = VideoGenerationRequest(
        song_id=song_id,
        start_line=start_line,
        end_line=end_line,
        custom_input=custom_input
    )
    
    # Step 1: Data Retrieval
    print("\nüì• STEP 1: Fetching data from Supabase...")
    retriever = DataRetriever()
    song, all_lyrics, target_lyrics, audio_path = retriever.fetch_all_data(request)
    print(f"‚úì Song: {song.title} by {song.artist}")
    print(f"‚úì Generating lines {start_line} to {target_lyrics[-1].line_number}")
    print(f"‚úì Total lines to generate: {len(target_lyrics)}")
    
    # Step 2: Style Planning
    print("\nüé® STEP 2: Creating style guide...")
    planner = StylePlanner()
    style_guide = planner.create_style_guide(song, all_lyrics, target_lyrics, custom_input)
    print(f"‚úì Visual Style: {style_guide.visual_style[:80]}...")
    print(f"‚úì Story: {style_guide.segment_story[:80]}...")
    print(f"‚úì Is Conversation: {style_guide.is_conversation}")
    
    # Step 3: Image Generation
    print("\nüñºÔ∏è  STEP 3: Generating images...")
    director = ImageDirector()
    images = director.generate_all_images(target_lyrics, style_guide, song_id, custom_input)
    print(f"‚úì Generated {len(images)} images")
    
    # Step 4: Video Assembly
    print("\nüé¨ STEP 4: Assembling video...")
    compositor = VideoCompositor()
    
    output_filename = f"song_{song_id}_lines_{start_line}-{target_lyrics[-1].line_number}.mp4"
    output_path = config.VIDEOS_DIR / output_filename
    
    final_video = compositor.assemble_video(images, target_lyrics, audio_path, output_path)
    
    # Save metadata
    metadata = {
        "song_id": song_id,
        "title": song.title,
        "artist": song.artist,
        "start_line": start_line,
        "end_line": target_lyrics[-1].line_number,
        "total_images": len(images),
        "style_guide": style_guide.dict(),
        "custom_input": custom_input.dict() if custom_input else None,
        "images": [img.dict() for img in images]
    }
    
    metadata_path = config.VIDEOS_DIR / f"{output_filename}.json"
    metadata_path.write_text(json.dumps(metadata, indent=2))
    
    print("\n" + "=" * 60)
    print("‚úÖ VIDEO GENERATION COMPLETE!")
    print(f"üìπ Video: {final_video}")
    print(f"üìÑ Metadata: {metadata_path}")
    print("=" * 60)
    
    # Step 5: Upload to Google Drive (optional)
    if upload_to_drive:
        print("\nüì§ STEP 5: Uploading to Google Drive...")
        try:
            uploader = DriveUploader()
            drive_result = uploader.upload_video(
                video_path=final_video,
                song_id=song_id,
                delete_after_upload=delete_after_upload
            )
            print("\n" + "=" * 60)
            print("‚úÖ UPLOAD COMPLETE!")
            print(f"üîó View on Drive: {drive_result['video_link']}")
            print("=" * 60)
            
        except Exception as e:
            print(f"\n‚ö†Ô∏è  Upload failed: {e}")
            print(f"üìπ Video saved locally: {final_video}")
    
    return final_video

if __name__ == "__main__":
    generate_lyric_video(
        song_id="f45fe486-128a-4acc-b77b-1afda459d574",
        start_line=1,
        end_line=16,
        custom_story="Digital illustration of a fierce pink cartoon teddy bear with a hyperpop street attitude walking through a lively Seoul city crosswalk, wearing edgy fashion like a black sleeveless top with a cracked heart emblem, a spiked choker, a pleated mini skirt with a chain, fishnet stockings, chunky platform boots, the bear‚Äôs determined expression showing bold confidence while surrounded by colorful Korean storefront signs, bright daylight reflections, and dynamic crowds, vibrant urban hues with saturated yellows, blues, and pinks, strong bold outlines and lively cartoon detailing, square composition with the bear dominating the center as it strides forward with attitude, capturing the playful chaos of pop culture and punk energy in a Seoul city vibe. IMPORTANT: The bear is the main character in the story. You dont even have to make two human charactesr appear. put focus on the bear.",
        upload_to_drive=False,
    )

    
#5f406392-77a2-43e3-b928-cf8ef62a291a
